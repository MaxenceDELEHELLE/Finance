{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a8fd91",
   "metadata": {},
   "source": [
    "# Auto Bayesian Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964219a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gmt time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.07.2020 00:00:00.000</td>\n",
       "      <td>1.12336</td>\n",
       "      <td>1.12336</td>\n",
       "      <td>1.12275</td>\n",
       "      <td>1.12306</td>\n",
       "      <td>4148.0298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.07.2020 01:00:00.000</td>\n",
       "      <td>1.12306</td>\n",
       "      <td>1.12395</td>\n",
       "      <td>1.12288</td>\n",
       "      <td>1.12385</td>\n",
       "      <td>5375.5801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.07.2020 02:00:00.000</td>\n",
       "      <td>1.12386</td>\n",
       "      <td>1.12406</td>\n",
       "      <td>1.12363</td>\n",
       "      <td>1.12382</td>\n",
       "      <td>4131.6099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.07.2020 03:00:00.000</td>\n",
       "      <td>1.12382</td>\n",
       "      <td>1.12388</td>\n",
       "      <td>1.12221</td>\n",
       "      <td>1.12265</td>\n",
       "      <td>4440.6001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.07.2020 04:00:00.000</td>\n",
       "      <td>1.12265</td>\n",
       "      <td>1.12272</td>\n",
       "      <td>1.12151</td>\n",
       "      <td>1.12179</td>\n",
       "      <td>4833.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01.07.2020 05:00:00.000</td>\n",
       "      <td>1.12179</td>\n",
       "      <td>1.12261</td>\n",
       "      <td>1.12156</td>\n",
       "      <td>1.12240</td>\n",
       "      <td>6689.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01.07.2020 06:00:00.000</td>\n",
       "      <td>1.12240</td>\n",
       "      <td>1.12343</td>\n",
       "      <td>1.12202</td>\n",
       "      <td>1.12333</td>\n",
       "      <td>7562.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01.07.2020 07:00:00.000</td>\n",
       "      <td>1.12331</td>\n",
       "      <td>1.12331</td>\n",
       "      <td>1.12231</td>\n",
       "      <td>1.12315</td>\n",
       "      <td>8641.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01.07.2020 08:00:00.000</td>\n",
       "      <td>1.12315</td>\n",
       "      <td>1.12448</td>\n",
       "      <td>1.12290</td>\n",
       "      <td>1.12311</td>\n",
       "      <td>10042.7695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01.07.2020 09:00:00.000</td>\n",
       "      <td>1.12313</td>\n",
       "      <td>1.12337</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>9587.4004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Gmt time     Open     High      Low    Close      Volume\n",
       "0  01.07.2020 00:00:00.000  1.12336  1.12336  1.12275  1.12306   4148.0298\n",
       "1  01.07.2020 01:00:00.000  1.12306  1.12395  1.12288  1.12385   5375.5801\n",
       "2  01.07.2020 02:00:00.000  1.12386  1.12406  1.12363  1.12382   4131.6099\n",
       "3  01.07.2020 03:00:00.000  1.12382  1.12388  1.12221  1.12265   4440.6001\n",
       "4  01.07.2020 04:00:00.000  1.12265  1.12272  1.12151  1.12179   4833.1001\n",
       "5  01.07.2020 05:00:00.000  1.12179  1.12261  1.12156  1.12240   6689.5601\n",
       "6  01.07.2020 06:00:00.000  1.12240  1.12343  1.12202  1.12333   7562.7500\n",
       "7  01.07.2020 07:00:00.000  1.12331  1.12331  1.12231  1.12315   8641.7500\n",
       "8  01.07.2020 08:00:00.000  1.12315  1.12448  1.12290  1.12311  10042.7695\n",
       "9  01.07.2020 09:00:00.000  1.12313  1.12337  1.12076  1.12076   9587.4004"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfo = pd.read_csv(\"EURUSD_Candlestick_1_Hour_BID_01.07.2020-15.07.2023.csv\")\n",
    "dfo=dfo[dfo['Volume']!=0]\n",
    "dfo.reset_index(drop=True, inplace=True)\n",
    "dfo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a5a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo['Gmt time'] = pd.to_datetime(dfo['Gmt time'], format='%d.%m.%Y %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d17371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(df, lookahead=5, threshold=0.002):\n",
    "    \"\"\"\n",
    "    Labels each candle based on future closing price percentage change.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Data containing at least a 'Close' column.\n",
    "    lookahead : int, optional\n",
    "        Number of candles to look ahead (default is 5).\n",
    "    threshold : float, optional\n",
    "        Percentage change threshold for classification (default is 0.002 or 0.2%).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute future percentage change in closing price\n",
    "    df[\"future_return\"] = df[\"Close\"].pct_change(lookahead).shift(-lookahead)\n",
    "\n",
    "    # Assign labels\n",
    "    df[\"label\"] = 0  # Default: Neutral\n",
    "    df.loc[df[\"future_return\"] > threshold, \"label\"] = 2  # Up\n",
    "    df.loc[df[\"future_return\"] < -threshold, \"label\"] = 1  # Down\n",
    "\n",
    "    # Drop future_return column (not needed in final output)\n",
    "    df.drop(columns=[\"future_return\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31df65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data(dfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea395d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gmt time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01 06:00:00</td>\n",
       "      <td>1.12240</td>\n",
       "      <td>1.12343</td>\n",
       "      <td>1.12202</td>\n",
       "      <td>1.12333</td>\n",
       "      <td>7562.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-07-01 09:00:00</td>\n",
       "      <td>1.12313</td>\n",
       "      <td>1.12337</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>9587.4004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-07-01 10:00:00</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>1.12113</td>\n",
       "      <td>1.12002</td>\n",
       "      <td>1.12050</td>\n",
       "      <td>11767.5898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-07-01 11:00:00</td>\n",
       "      <td>1.12050</td>\n",
       "      <td>1.12067</td>\n",
       "      <td>1.11848</td>\n",
       "      <td>1.12036</td>\n",
       "      <td>14733.7998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-07-01 12:00:00</td>\n",
       "      <td>1.12036</td>\n",
       "      <td>1.12209</td>\n",
       "      <td>1.11980</td>\n",
       "      <td>1.12177</td>\n",
       "      <td>13410.0596</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17735</th>\n",
       "      <td>2023-07-13 12:00:00</td>\n",
       "      <td>1.11742</td>\n",
       "      <td>1.11897</td>\n",
       "      <td>1.11615</td>\n",
       "      <td>1.11795</td>\n",
       "      <td>39235.5900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17736</th>\n",
       "      <td>2023-07-13 13:00:00</td>\n",
       "      <td>1.11797</td>\n",
       "      <td>1.11949</td>\n",
       "      <td>1.11761</td>\n",
       "      <td>1.11942</td>\n",
       "      <td>35069.8900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17737</th>\n",
       "      <td>2023-07-13 14:00:00</td>\n",
       "      <td>1.11943</td>\n",
       "      <td>1.11959</td>\n",
       "      <td>1.11806</td>\n",
       "      <td>1.11957</td>\n",
       "      <td>26614.8000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17738</th>\n",
       "      <td>2023-07-13 15:00:00</td>\n",
       "      <td>1.11959</td>\n",
       "      <td>1.11965</td>\n",
       "      <td>1.11858</td>\n",
       "      <td>1.11927</td>\n",
       "      <td>20519.5900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17748</th>\n",
       "      <td>2023-07-14 01:00:00</td>\n",
       "      <td>1.12227</td>\n",
       "      <td>1.12336</td>\n",
       "      <td>1.12221</td>\n",
       "      <td>1.12329</td>\n",
       "      <td>19807.7400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4753 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Gmt time     Open     High      Low    Close      Volume  \\\n",
       "6     2020-07-01 06:00:00  1.12240  1.12343  1.12202  1.12333   7562.7500   \n",
       "9     2020-07-01 09:00:00  1.12313  1.12337  1.12076  1.12076   9587.4004   \n",
       "10    2020-07-01 10:00:00  1.12076  1.12113  1.12002  1.12050  11767.5898   \n",
       "11    2020-07-01 11:00:00  1.12050  1.12067  1.11848  1.12036  14733.7998   \n",
       "12    2020-07-01 12:00:00  1.12036  1.12209  1.11980  1.12177  13410.0596   \n",
       "...                   ...      ...      ...      ...      ...         ...   \n",
       "17735 2023-07-13 12:00:00  1.11742  1.11897  1.11615  1.11795  39235.5900   \n",
       "17736 2023-07-13 13:00:00  1.11797  1.11949  1.11761  1.11942  35069.8900   \n",
       "17737 2023-07-13 14:00:00  1.11943  1.11959  1.11806  1.11957  26614.8000   \n",
       "17738 2023-07-13 15:00:00  1.11959  1.11965  1.11858  1.11927  20519.5900   \n",
       "17748 2023-07-14 01:00:00  1.12227  1.12336  1.12221  1.12329  19807.7400   \n",
       "\n",
       "       label  \n",
       "6          1  \n",
       "9          2  \n",
       "10         2  \n",
       "11         2  \n",
       "12         2  \n",
       "...      ...  \n",
       "17735      2  \n",
       "17736      2  \n",
       "17737      2  \n",
       "17738      2  \n",
       "17748      1  \n",
       "\n",
       "[4753 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfo[dfo[\"label\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89005cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 12:19:31.114822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745317171.164126   10924 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745317171.178659   10924 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745317171.295025   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745317171.295043   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745317171.295045   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745317171.295046   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import autobnn as ab\n",
    "import jax\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def create_sliding_window_dataset(df, window_size=50, lookahead=5, threshold=0.002):\n",
    "    if \"Close\" not in df.columns or \"label\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'Close' and 'label' columns.\")\n",
    "\n",
    "    label_data(df=df, lookahead=lookahead, threshold=threshold)\n",
    "\n",
    "    close_prices = df[\"Close\"].values\n",
    "    labels = df[\"label\"].values\n",
    "\n",
    "    n_samples = len(df) - window_size\n",
    "    if n_samples <= 0:\n",
    "        raise ValueError(\"Not enough data to create even one window.\"\n",
    "                         \"Increase your dataset or decrease window_size.\")\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        window_data = close_prices[i : i + window_size]\n",
    "        last_candle_label = labels[i + window_size - 1] # label of the last candle in window_size\n",
    "        X_list.append(window_data)\n",
    "        y_list.append(last_candle_label)\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43748f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = create_sliding_window_dataset(dfo)\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e5f53a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flowMC.nfmodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m dfsample \u001b[38;5;241m=\u001b[39m dfo[:\u001b[38;5;241m1000\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mwalk_forward_autobnn_ovr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdfsample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.002\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# e.g. for classes {0,1,2}\u001b[39;49;00m\n\u001b[1;32m    123\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracies:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[9], line 81\u001b[0m, in \u001b[0;36mwalk_forward_autobnn_ovr\u001b[0;34m(df, window_size, train_size, step_size, threshold, n_classes)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Use the likelihood your autobnn version actually recognizes:\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# 'normal_likelihood_logistic_noise' is a hacky approach but workable if recognized.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     estimator_c \u001b[38;5;241m=\u001b[39m ab\u001b[38;5;241m.\u001b[39mestimators\u001b[38;5;241m.\u001b[39mAutoBnnMapEstimator(\n\u001b[1;32m     73\u001b[0m         model_c,\n\u001b[1;32m     74\u001b[0m         likelihood_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal_likelihood_logistic_noise\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;66;03m# but you can pass k=2 if your version allows it. \u001b[39;00m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mestimator_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     estimators\u001b[38;5;241m.\u001b[39mappend(estimator_c)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# 4. Predict probabilities for each class on the single test sample\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#    'normal_likelihood_logistic_noise' typically returns shape (1,2): [mean, var]\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m#    We'll interpret the 'mean' as a *logit*, i.e. log-odds, and do logistic transform.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/autobnn/estimators.py:101\u001b[0m, in \u001b[0;36m_AutoBnnEstimator.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_ \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mmake_model(\n\u001b[1;32m     94\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_or_name,\n\u001b[1;32m     95\u001b[0m     likelihood_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperiods,\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_seed_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_quantiles_seed_ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiagnostics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/autobnn/training_util.py:156\u001b[0m, in \u001b[0;36mfit_bnn_map\u001b[0;34m(net, seed, x_train, y_train, num_particles, **optimizer_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m optimizer_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_particles\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m num_particles\n\u001b[1;32m    155\u001b[0m model_seed, optimization_seed \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(seed)\n\u001b[0;32m--> 156\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_make_bayeux_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39moptax_adam(seed\u001b[38;5;241m=\u001b[39moptimization_seed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptimizer_kwargs)  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    158\u001b[0m params \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mparams\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/autobnn/training_util.py:107\u001b[0m, in \u001b[0;36m_make_bayeux_model\u001b[0;34m(net, seed, x_train, y_train, num_particles, for_vi)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use a MAP estimator to fit a BNN.\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# We can't import bayeux at the file level because it would create a\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# circular dependency:  autobnn imports bayeux imports tfp:jax\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# which in turn imports (through __init__.py files) autobnn.\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbx\u001b[39;00m  \u001b[38;5;66;03m# pylint:disable=g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m    109\u001b[0m transform, inverse_transform, ildj \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mmake_transforms(net)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_init\u001b[39m(rand_seed):\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/bayeux/__init__.py:24\u001b[0m\n\u001b[1;32m     19\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.1.15\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Note: import <name> as <name> is required for names to be exported.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# See PEP 484 & https://github.com/google/jax/issues/7570\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# pylint: disable=useless-import-alias\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mcmc \u001b[38;5;28;01mas\u001b[39;00m mcmc\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize \u001b[38;5;28;01mas\u001b[39;00m optimize\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m debug \u001b[38;5;28;01mas\u001b[39;00m debug\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/bayeux/mcmc/__init__.py:39\u001b[0m\n\u001b[1;32m     34\u001b[0m   __all__\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHMCblackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheesHMCblackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeadsHMCblackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUTSblackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHMC_Pathfinder_blackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUTS_Pathfinder_blackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflowMC\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmcmc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflowmc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaskedCouplingRQSplineHMC \u001b[38;5;28;01mas\u001b[39;00m MaskedCouplingRQSplineHMCflowmc\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmcmc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflowmc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaskedCouplingRQSplineMALA \u001b[38;5;28;01mas\u001b[39;00m MaskedCouplingRQSplineMALAflowmc\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmcmc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflowmc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RealNVPHMC \u001b[38;5;28;01mas\u001b[39;00m RealNVPHMCflowmc\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/bayeux/_src/mcmc/flowmc.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbayeux\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m shared\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflowMC\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sampler\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflowMC\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnfmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m realNVP\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflowMC\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnfmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rqSpline\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflowMC\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproposal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HMC\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flowMC.nfmodel'"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import autobnn as ab\n",
    "from autobnn import estimators, operators, kernels\n",
    "\n",
    "def walk_forward_autobnn_ovr(\n",
    "    df, \n",
    "    window_size=100,\n",
    "    train_size=50,\n",
    "    step_size=5,\n",
    "    threshold=0.002,\n",
    "    n_classes=3  # e.g., if labels are {0,1,2}\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-class classification via One-vs-Rest using AutoBNN,\n",
    "    specifically using 'normal_likelihood_logistic_noise' for each binary classifier.\n",
    "    \n",
    "    Steps:\n",
    "      1) create_sliding_window_dataset(...) -> (X, y)\n",
    "         X: (n_samples, n_features), y: (n_samples,) with integer classes\n",
    "      2) For each walk-forward iteration:\n",
    "         - Train n_classes binary models, each \"Does y == c?\" -> 0/1\n",
    "         - At prediction time, get each model's 'logit' => logistic transform => probability\n",
    "         - Argmax over classes => final predicted class\n",
    "      3) Return single-sample accuracies for each step.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Build your dataset\n",
    "    X, y = create_sliding_window_dataset(df=df, window_size=window_size, threshold=threshold)\n",
    "    n_total = len(X)\n",
    "    # print(X, n_total)\n",
    "    if n_total < train_size + 1:\n",
    "        raise ValueError(\"Not enough samples for walk-forward analysis.\")\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # 2. Walk-forward loop\n",
    "    for i in range(0, n_total - train_size, step_size):\n",
    "        X_train = X[i : i + train_size]\n",
    "        y_train = y[i : i + train_size]\n",
    "\n",
    "        test_index = i + train_size\n",
    "        if test_index >= n_total:\n",
    "            break\n",
    "\n",
    "        X_test = X[test_index : test_index + 1]  # shape (1, features)\n",
    "        y_test = y[test_index : test_index + 1]  # shape (1,)\n",
    "\n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "        # 3. Train one binary model per class\n",
    "        estimators = []\n",
    "        for c in range(n_classes):\n",
    "            # Make binary labels: 1 if y == c, else 0\n",
    "            y_train_c = (y_train == c).astype(int)\n",
    "\n",
    "            model_c = ab.operators.Add(\n",
    "                bnns=(\n",
    "                    ab.kernels.PeriodicBNN(width=20, period=12.0),\n",
    "                    ab.kernels.LinearBNN(width=20),\n",
    "                    ab.kernels.MaternBNN(width=20),\n",
    "                )\n",
    "            )\n",
    "            # Use the likelihood your autobnn version actually recognizes:\n",
    "            # 'normal_likelihood_logistic_noise' is a hacky approach but workable if recognized.\n",
    "            estimator_c = ab.estimators.AutoBnnMapEstimator(\n",
    "                model_c,\n",
    "                likelihood_model=\"normal_likelihood_logistic_noise\",  \n",
    "                seed=jax.random.PRNGKey(42),\n",
    "                periods=[12],\n",
    "                # We do not set k=2 because it's not a pure classification wrapper,\n",
    "                # but you can pass k=2 if your version allows it. \n",
    "            )\n",
    "\n",
    "            estimator_c.fit(X_train_scaled, y_train_c)\n",
    "            estimators.append(estimator_c)\n",
    "\n",
    "        # 4. Predict probabilities for each class on the single test sample\n",
    "        #    'normal_likelihood_logistic_noise' typically returns shape (1,2): [mean, var]\n",
    "        #    We'll interpret the 'mean' as a *logit*, i.e. log-odds, and do logistic transform.\n",
    "        class_probs = []\n",
    "        for c in range(n_classes):\n",
    "            y_pred_c = estimators[c].predict(X_test_scaled)  # shape (1,2) or (1,)?\n",
    "            \n",
    "            # If it returns shape (1,2) => [ [mean, var] ],\n",
    "            # we take the 0th column as mean (the \"logit\").\n",
    "            # In some versions, it might be shape (1,) -> just the mean. \n",
    "            if y_pred_c.ndim == 2:\n",
    "                logit = y_pred_c[0, 0]  # first row, mean col\n",
    "            else:\n",
    "                # shape (1,) => just the mean\n",
    "                logit = y_pred_c[0]\n",
    "            \n",
    "            # Convert logit -> probability: prob = 1 / (1 + exp(-logit))\n",
    "            prob_c = 1.0 / (1.0 + np.exp(-logit))\n",
    "            class_probs.append(prob_c)\n",
    "\n",
    "        # 5. Pick the class with the highest probability\n",
    "        y_pred_class = np.argmax(class_probs)  # integer c in [0..n_classes-1]\n",
    "\n",
    "        # 6. Single-sample accuracy (0 or 1)\n",
    "        acc = accuracy_score(y_test, [y_pred_class])\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "dfsample = dfo[:1000].copy()\n",
    "\n",
    "# Example usage:\n",
    "results = walk_forward_autobnn_ovr(\n",
    "    df=dfsample,\n",
    "    window_size=40,\n",
    "    train_size=20,\n",
    "    step_size=5,\n",
    "    threshold=0.002,\n",
    "    n_classes=3  # e.g. for classes {0,1,2}\n",
    ")\n",
    "\n",
    "print(\"Accuracies:\", results)\n",
    "if results:\n",
    "    print(\"Mean Accuracy:\", np.mean(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea5f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0180d8-1bda-4089-9349-ad0da0c40b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95595f7-0ad6-4449-88b8-8e823fb48b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

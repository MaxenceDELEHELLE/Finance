{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a8fd91",
   "metadata": {},
   "source": [
    "# Auto Bayesian Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964219a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gmt time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.07.2020 00:00:00.000</td>\n",
       "      <td>1.12336</td>\n",
       "      <td>1.12336</td>\n",
       "      <td>1.12275</td>\n",
       "      <td>1.12306</td>\n",
       "      <td>4148.0298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.07.2020 01:00:00.000</td>\n",
       "      <td>1.12306</td>\n",
       "      <td>1.12395</td>\n",
       "      <td>1.12288</td>\n",
       "      <td>1.12385</td>\n",
       "      <td>5375.5801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.07.2020 02:00:00.000</td>\n",
       "      <td>1.12386</td>\n",
       "      <td>1.12406</td>\n",
       "      <td>1.12363</td>\n",
       "      <td>1.12382</td>\n",
       "      <td>4131.6099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.07.2020 03:00:00.000</td>\n",
       "      <td>1.12382</td>\n",
       "      <td>1.12388</td>\n",
       "      <td>1.12221</td>\n",
       "      <td>1.12265</td>\n",
       "      <td>4440.6001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.07.2020 04:00:00.000</td>\n",
       "      <td>1.12265</td>\n",
       "      <td>1.12272</td>\n",
       "      <td>1.12151</td>\n",
       "      <td>1.12179</td>\n",
       "      <td>4833.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01.07.2020 05:00:00.000</td>\n",
       "      <td>1.12179</td>\n",
       "      <td>1.12261</td>\n",
       "      <td>1.12156</td>\n",
       "      <td>1.12240</td>\n",
       "      <td>6689.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01.07.2020 06:00:00.000</td>\n",
       "      <td>1.12240</td>\n",
       "      <td>1.12343</td>\n",
       "      <td>1.12202</td>\n",
       "      <td>1.12333</td>\n",
       "      <td>7562.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01.07.2020 07:00:00.000</td>\n",
       "      <td>1.12331</td>\n",
       "      <td>1.12331</td>\n",
       "      <td>1.12231</td>\n",
       "      <td>1.12315</td>\n",
       "      <td>8641.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01.07.2020 08:00:00.000</td>\n",
       "      <td>1.12315</td>\n",
       "      <td>1.12448</td>\n",
       "      <td>1.12290</td>\n",
       "      <td>1.12311</td>\n",
       "      <td>10042.7695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01.07.2020 09:00:00.000</td>\n",
       "      <td>1.12313</td>\n",
       "      <td>1.12337</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>9587.4004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Gmt time     Open     High      Low    Close      Volume\n",
       "0  01.07.2020 00:00:00.000  1.12336  1.12336  1.12275  1.12306   4148.0298\n",
       "1  01.07.2020 01:00:00.000  1.12306  1.12395  1.12288  1.12385   5375.5801\n",
       "2  01.07.2020 02:00:00.000  1.12386  1.12406  1.12363  1.12382   4131.6099\n",
       "3  01.07.2020 03:00:00.000  1.12382  1.12388  1.12221  1.12265   4440.6001\n",
       "4  01.07.2020 04:00:00.000  1.12265  1.12272  1.12151  1.12179   4833.1001\n",
       "5  01.07.2020 05:00:00.000  1.12179  1.12261  1.12156  1.12240   6689.5601\n",
       "6  01.07.2020 06:00:00.000  1.12240  1.12343  1.12202  1.12333   7562.7500\n",
       "7  01.07.2020 07:00:00.000  1.12331  1.12331  1.12231  1.12315   8641.7500\n",
       "8  01.07.2020 08:00:00.000  1.12315  1.12448  1.12290  1.12311  10042.7695\n",
       "9  01.07.2020 09:00:00.000  1.12313  1.12337  1.12076  1.12076   9587.4004"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfo = pd.read_csv(\"EURUSD_Candlestick_1_Hour_BID_01.07.2020-15.07.2023.csv\")\n",
    "dfo=dfo[dfo['Volume']!=0]\n",
    "dfo.reset_index(drop=True, inplace=True)\n",
    "dfo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a5a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo['Gmt time'] = pd.to_datetime(dfo['Gmt time'], format='%d.%m.%Y %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d17371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(df, lookahead=5, threshold=0.002):\n",
    "    \"\"\"\n",
    "    Labels each candle based on future closing price percentage change.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Data containing at least a 'Close' column.\n",
    "    lookahead : int, optional\n",
    "        Number of candles to look ahead (default is 5).\n",
    "    threshold : float, optional\n",
    "        Percentage change threshold for classification (default is 0.002 or 0.2%).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute future percentage change in closing price\n",
    "    df[\"future_return\"] = df[\"Close\"].pct_change(lookahead).shift(-lookahead)\n",
    "\n",
    "    # Assign labels\n",
    "    df[\"label\"] = 0  # Default: Neutral\n",
    "    df.loc[df[\"future_return\"] > threshold, \"label\"] = 2  # Up\n",
    "    df.loc[df[\"future_return\"] < -threshold, \"label\"] = 1  # Down\n",
    "\n",
    "    # Drop future_return column (not needed in final output)\n",
    "    df.drop(columns=[\"future_return\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31df65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data(dfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea395d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gmt time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01 06:00:00</td>\n",
       "      <td>1.12240</td>\n",
       "      <td>1.12343</td>\n",
       "      <td>1.12202</td>\n",
       "      <td>1.12333</td>\n",
       "      <td>7562.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-07-01 09:00:00</td>\n",
       "      <td>1.12313</td>\n",
       "      <td>1.12337</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>9587.4004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-07-01 10:00:00</td>\n",
       "      <td>1.12076</td>\n",
       "      <td>1.12113</td>\n",
       "      <td>1.12002</td>\n",
       "      <td>1.12050</td>\n",
       "      <td>11767.5898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-07-01 11:00:00</td>\n",
       "      <td>1.12050</td>\n",
       "      <td>1.12067</td>\n",
       "      <td>1.11848</td>\n",
       "      <td>1.12036</td>\n",
       "      <td>14733.7998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-07-01 12:00:00</td>\n",
       "      <td>1.12036</td>\n",
       "      <td>1.12209</td>\n",
       "      <td>1.11980</td>\n",
       "      <td>1.12177</td>\n",
       "      <td>13410.0596</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17735</th>\n",
       "      <td>2023-07-13 12:00:00</td>\n",
       "      <td>1.11742</td>\n",
       "      <td>1.11897</td>\n",
       "      <td>1.11615</td>\n",
       "      <td>1.11795</td>\n",
       "      <td>39235.5900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17736</th>\n",
       "      <td>2023-07-13 13:00:00</td>\n",
       "      <td>1.11797</td>\n",
       "      <td>1.11949</td>\n",
       "      <td>1.11761</td>\n",
       "      <td>1.11942</td>\n",
       "      <td>35069.8900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17737</th>\n",
       "      <td>2023-07-13 14:00:00</td>\n",
       "      <td>1.11943</td>\n",
       "      <td>1.11959</td>\n",
       "      <td>1.11806</td>\n",
       "      <td>1.11957</td>\n",
       "      <td>26614.8000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17738</th>\n",
       "      <td>2023-07-13 15:00:00</td>\n",
       "      <td>1.11959</td>\n",
       "      <td>1.11965</td>\n",
       "      <td>1.11858</td>\n",
       "      <td>1.11927</td>\n",
       "      <td>20519.5900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17748</th>\n",
       "      <td>2023-07-14 01:00:00</td>\n",
       "      <td>1.12227</td>\n",
       "      <td>1.12336</td>\n",
       "      <td>1.12221</td>\n",
       "      <td>1.12329</td>\n",
       "      <td>19807.7400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4753 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Gmt time     Open     High      Low    Close      Volume  \\\n",
       "6     2020-07-01 06:00:00  1.12240  1.12343  1.12202  1.12333   7562.7500   \n",
       "9     2020-07-01 09:00:00  1.12313  1.12337  1.12076  1.12076   9587.4004   \n",
       "10    2020-07-01 10:00:00  1.12076  1.12113  1.12002  1.12050  11767.5898   \n",
       "11    2020-07-01 11:00:00  1.12050  1.12067  1.11848  1.12036  14733.7998   \n",
       "12    2020-07-01 12:00:00  1.12036  1.12209  1.11980  1.12177  13410.0596   \n",
       "...                   ...      ...      ...      ...      ...         ...   \n",
       "17735 2023-07-13 12:00:00  1.11742  1.11897  1.11615  1.11795  39235.5900   \n",
       "17736 2023-07-13 13:00:00  1.11797  1.11949  1.11761  1.11942  35069.8900   \n",
       "17737 2023-07-13 14:00:00  1.11943  1.11959  1.11806  1.11957  26614.8000   \n",
       "17738 2023-07-13 15:00:00  1.11959  1.11965  1.11858  1.11927  20519.5900   \n",
       "17748 2023-07-14 01:00:00  1.12227  1.12336  1.12221  1.12329  19807.7400   \n",
       "\n",
       "       label  \n",
       "6          1  \n",
       "9          2  \n",
       "10         2  \n",
       "11         2  \n",
       "12         2  \n",
       "...      ...  \n",
       "17735      2  \n",
       "17736      2  \n",
       "17737      2  \n",
       "17738      2  \n",
       "17748      1  \n",
       "\n",
       "[4753 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfo[dfo[\"label\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89005cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 12:19:31.114822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745317171.164126   10924 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745317171.178659   10924 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745317171.295025   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745317171.295043   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745317171.295045   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745317171.295046   10924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import autobnn as ab\n",
    "import jax\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def create_sliding_window_dataset(df, window_size=50, lookahead=5, threshold=0.002):\n",
    "    if \"Close\" not in df.columns or \"label\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'Close' and 'label' columns.\")\n",
    "\n",
    "    label_data(df=df, lookahead=lookahead, threshold=threshold)\n",
    "\n",
    "    close_prices = df[\"Close\"].values\n",
    "    labels = df[\"label\"].values\n",
    "\n",
    "    n_samples = len(df) - window_size\n",
    "    if n_samples <= 0:\n",
    "        raise ValueError(\"Not enough data to create even one window.\"\n",
    "                         \"Increase your dataset or decrease window_size.\")\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        window_data = close_prices[i : i + window_size]\n",
    "        last_candle_label = labels[i + window_size - 1] # label of the last candle in window_size\n",
    "        X_list.append(window_data)\n",
    "        y_list.append(last_candle_label)\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43748f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = create_sliding_window_dataset(dfo)\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import autobnn as ab\n",
    "from autobnn import estimators, operators, kernels\n",
    "\n",
    "def walk_forward_autobnn_ovr(\n",
    "    df, \n",
    "    window_size=100,\n",
    "    train_size=50,\n",
    "    step_size=5,\n",
    "    threshold=0.002,\n",
    "    n_classes=3  # e.g., if labels are {0,1,2}\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-class classification via One-vs-Rest using AutoBNN,\n",
    "    specifically using 'normal_likelihood_logistic_noise' for each binary classifier.\n",
    "    \n",
    "    Steps:\n",
    "      1) create_sliding_window_dataset(...) -> (X, y)\n",
    "         X: (n_samples, n_features), y: (n_samples,) with integer classes\n",
    "      2) For each walk-forward iteration:\n",
    "         - Train n_classes binary models, each \"Does y == c?\" -> 0/1\n",
    "         - At prediction time, get each model's 'logit' => logistic transform => probability\n",
    "         - Argmax over classes => final predicted class\n",
    "      3) Return single-sample accuracies for each step.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Build your dataset\n",
    "    X, y = create_sliding_window_dataset(df=df, window_size=window_size, threshold=threshold)\n",
    "    n_total = len(X)\n",
    "    # print(X, n_total)\n",
    "    if n_total < train_size + 1:\n",
    "        raise ValueError(\"Not enough samples for walk-forward analysis.\")\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # 2. Walk-forward loop\n",
    "    for i in range(0, n_total - train_size, step_size):\n",
    "        X_train = X[i : i + train_size]\n",
    "        y_train = y[i : i + train_size]\n",
    "\n",
    "        test_index = i + train_size\n",
    "        if test_index >= n_total:\n",
    "            break\n",
    "\n",
    "        X_test = X[test_index : test_index + 1]  # shape (1, features)\n",
    "        y_test = y[test_index : test_index + 1]  # shape (1,)\n",
    "\n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "        # 3. Train one binary model per class\n",
    "        estimators = []\n",
    "        for c in range(n_classes):\n",
    "            # Make binary labels: 1 if y == c, else 0\n",
    "            y_train_c = (y_train == c).astype(int)\n",
    "\n",
    "            model_c = ab.operators.Add(\n",
    "                bnns=(\n",
    "                    ab.kernels.PeriodicBNN(width=20, period=12.0),\n",
    "                    ab.kernels.LinearBNN(width=20),\n",
    "                    ab.kernels.MaternBNN(width=20),\n",
    "                )\n",
    "            )\n",
    "            # Use the likelihood your autobnn version actually recognizes:\n",
    "            # 'normal_likelihood_logistic_noise' is a hacky approach but workable if recognized.\n",
    "            estimator_c = ab.estimators.AutoBnnMapEstimator(\n",
    "                model_c,\n",
    "                likelihood_model=\"normal_likelihood_logistic_noise\",  \n",
    "                seed=jax.random.PRNGKey(42),\n",
    "                periods=[12],\n",
    "                # We do not set k=2 because it's not a pure classification wrapper,\n",
    "                # but you can pass k=2 if your version allows it. \n",
    "            )\n",
    "\n",
    "            estimator_c.fit(X_train_scaled, y_train_c)\n",
    "            estimators.append(estimator_c)\n",
    "\n",
    "        # 4. Predict probabilities for each class on the single test sample\n",
    "        #    'normal_likelihood_logistic_noise' typically returns shape (1,2): [mean, var]\n",
    "        #    We'll interpret the 'mean' as a *logit*, i.e. log-odds, and do logistic transform.\n",
    "        class_probs = []\n",
    "        for c in range(n_classes):\n",
    "            y_pred_c = estimators[c].predict(X_test_scaled)  # shape (1,2) or (1,)?\n",
    "            \n",
    "            # If it returns shape (1,2) => [ [mean, var] ],\n",
    "            # we take the 0th column as mean (the \"logit\").\n",
    "            # In some versions, it might be shape (1,) -> just the mean. \n",
    "            if y_pred_c.ndim == 2:\n",
    "                logit = y_pred_c[0, 0]  # first row, mean col\n",
    "            else:\n",
    "                # shape (1,) => just the mean\n",
    "                logit = y_pred_c[0]\n",
    "            \n",
    "            # Convert logit -> probability: prob = 1 / (1 + exp(-logit))\n",
    "            prob_c = 1.0 / (1.0 + np.exp(-logit))\n",
    "            class_probs.append(prob_c)\n",
    "\n",
    "        # 5. Pick the class with the highest probability\n",
    "        y_pred_class = np.argmax(class_probs)  # integer c in [0..n_classes-1]\n",
    "\n",
    "        # 6. Single-sample accuracy (0 or 1)\n",
    "        acc = accuracy_score(y_test, [y_pred_class])\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "dfsample = dfo[:1000].copy()\n",
    "\n",
    "# Example usage:\n",
    "results = walk_forward_autobnn_ovr(\n",
    "    df=dfsample,\n",
    "    window_size=40,\n",
    "    train_size=20,\n",
    "    step_size=5,\n",
    "    threshold=0.002,\n",
    "    n_classes=3  # e.g. for classes {0,1,2}\n",
    ")\n",
    "\n",
    "print(\"Accuracies:\", results)\n",
    "if results:\n",
    "    print(\"Mean Accuracy:\", np.mean(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea5f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0180d8-1bda-4089-9349-ad0da0c40b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95595f7-0ad6-4449-88b8-8e823fb48b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
